## mdfrontserver

* 2017.08.04,由于阿里云slb，11:56有次中断，导致堆积的请求集中打入，造成线程堆积，服务器响应慢，进而负责接收下单请求和支付成功回调处理的mdfrontserver线程大量堆积，从而md_pay_queue表大量堆积待处理的记录，造成订单延迟！

## mdpaygate

### 确认consumeQueue是否堆积导致延迟

>  * 曾经广告项目导致shopcenter打穿redis，直接访问数据库导致shopcenter慢，进而连锁反映到mdfrontserver提取shopcenter信息慢，进而导致consumeQueue堆积。
>  * mdtradecenter配置了rdm主从合一数据库连接，导致虽然绑定成功，但在mdfrontserver的paycallback的回调处理失败，order_status字段因主从延迟而不一致，导致consumeQueue消费失败，进而堆积。

### 消费失败的consume failed查询语句

目前消费重试机制

  * 重试第一次，10秒后开始
  * 重试第二次，1分钟后开始
  * 重试第三次，5分钟后开始
  * 重试第四次，15分钟后开始
  * 重试第五次，60分钟后开始
  * 重试第六次，2小时后开始
  * 重试第七次，5小时后开始
  * 重试第八次，10小时后开始

* 八次以后，status设置为作废状态(4)，consume_status设置为消费成功（2）
* 正常状态，status应该设置为删除状态（5）也代表frontserver处理成功返回success,consume_status设置为（2）

```sql

select * from mdpay.md_pay_queue_bak where status = 4 and create_time>UNIX_TIMESTAMP('2017-08-06 18:00')*1000 and consume_count>1

```

### 2017.08.06失败原因

* 取unionid的接口当了，导致mdpaygate线程堆积，进而导致绑定订单大量失败，这里未采用线程池，也不恰当设置给unionid设置了6秒超时，重点采用连接池问题，还有个隐藏问题那就是，dubbo下增加服务器，负载是否均衡分布过来需要待查。
* 现在支付的渠道下单失败也造成了部分影响。
* 绑定订单失败这个梗为何迟迟不能恢复也要细查。
* 2017.08.07中午又出现了故障，基本定位是IIS自动回收关闭导致，导致大量垃圾内存无法回收，今天暂时去掉了b->c的unionid提取，另外，unionid提取单分配站点。目前这块架构存在死循环模式，即newwap等frontserver,paygate等newwap，导致互相线程大量堆积不可收拾。
* 继续...mdtask有一个select语句采用 md_order_info forceindex(pa_status)进行了优化
* 调取现在支付超时时长从6秒调回3秒
* 今儿考虑分离queue队列的处理和现在支付采用http线程池，昨天彪彪还调整了mdfrontserver的resin线程池配置且将mdfrontserver追加到8台
* 另外dubbo负载均衡事宜待解决。
     * <table><tr><td bgcolor="Teal"><font color="white">dubbo问题解决，原因是新机器的hosts文件还是老的，此时采用cat /etc/hosts发现ip还是老的，那么从dubbomonitor.log能看到注册的ip地址采用的是hosts而无效，更改过来后正常</font></td></tr></table>
* 发现部分因为上线而无效的queue数据，如下：

```sql
select *,FROM_UNIXTIME(create_time/1000),FROM_UNIXTIME(last_consume_time/1000) from mdpay.md_pay_queue
where create_time<UNIX_TIMESTAMP('2017-08-08 01:00:00')*1000 and create_time>UNIX_TIMESTAMP('2017-08-06 17:00:00')*1000	and last_consume_time is null

```
* 目前可分离的模块queue处理或者接notify更合理？，当前可先调为1000，因为高峰期堆积可到13000左右，除以6大概是2000左右，目前调到500
* 另外，提取queue数据后也应该批量开线程处理，而不是for循环单线程处理。
    * ![dbMsgConsumer](images/08/dbMsgConsumer.jpg)
```bash
cat common-default.log.2017080812|grep -E "dbMsgConsumer.{1,}此次更新[0-9]{1,}条" --color=auto
cat common-defalut.log.2017080812|grep -E "cost6:3[0-9]{3,}.{1,},slow" --color=auto
cat common-default.log|grep -E "2017-08-08 17:5.{1,}notify inner.{1,},Time:[0-9]{1,}," -c
```
* 触发点可能是现在支付出现了较多的3秒超时，但不应该导致我们系统崩溃，这个根除途径是分离queue处理系统以及采用httpclient线程池，一是提高性能一是减少线程切换等等。

#### 正常堆积判断语句

<table><tr><td bgcolor="Teal"><font color="white">select count(*) from mdpay.md_pay_queue where consume_status!=2</font></td></tr></table>

#### 特定时段consumequeue超过1分钟处理的延时堆积

```sql
select trade_no ,consume_count,FROM_UNIXTIME(create_time/1000,'%Y-%m-%d %T') add_time, FROM_UNIXTIME(last_consume_time/1000,'%Y-%m-%d %T') last_time from md_pay_queue_bak where consume_status=2 and create_time>UNIX_TIMESTAMP('2017-07-18 12:00')*1000 and create_time<UNIX_TIMESTAMP('2017-07-18 14:00')*1000  and (last_consume_time - create_time>60000) order by id desc;
```

#### remedy补单

```sql
select order_id,FROM_UNIXTIME(add_time/1000) as atime,
FROM_UNIXTIME(last_remedy_time/1000) as ltime,remedy_count from remedyorder order by order_id desc;
```


### 多码合一 c扫b 回调
> * c->b回调慢也有原因是我们的网络架构不合理，ngix上集成了太多项目的负载，后来做了调整。

### 被扫，扫码机的b扫c，延迟
> * 曾经有入consumequeue时取redis锁失败导致丢单依赖补单
> * 现在支付持续返回A004导致丢单依赖补单
> * mysql的Dead lock导致丢单依赖补单
> * hashmap未采用多线程版本concurrentHashMap，导致时间转换失败，已修正，此前采用多尝试一次机制也能很大改善。

### dubbo分发链接处理

> * 鉴于要根据链接区分服务器，对微信和支付宝通道在nginx上根据链接做区分，为此修改dubbo配置

#### 客户端dubbo配置修改

> * 这里采用了同样的**interface**，不同的bean id。

![dubbo reference](images/07/dubbo-ref-clientside.jpg)

#### 服务端dubbo配置修改

> * 这里同样采用了相同的**ref bean**引用，不同的**path**配置，<font color=LightCoral>注意这里path必须客户端配置的id完全相同!</font>

![dubbo service](images/07/dubbo-service-serverside.jpg)

#### Java程序中如此应用

```java
    @Autowired
    private TradeService tradeService;

    @Autowired
    private TradeService alipayTradeService;
```

## notifyserver
> * 必须消息缓存体和队列缓存体分开，不能是同一服务器同一端口的redis，否则无法正常工作。

## 运维
> * 镜像虚拟机时，host配置必须修改，否则重复导致无法访问到。
